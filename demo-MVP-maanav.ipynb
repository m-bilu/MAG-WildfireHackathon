{"cells":[{"cell_type":"markdown","metadata":{"id":"3VTfx8boPuBT"},"source":["# Demo CNN for Wildfire Growth Prediction\n","\n","Below is starter code for a cnn solution to solve the wildfire growth challenge!\n","\n","We provide infrastructure and helper functions to call and process the data.\n","\n","It is up to your team to fill in necessary blanks and improve the pipeline."]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":261,"status":"ok","timestamp":1716667451430,"user":{"displayName":"Maanav Rajesh","userId":"00079058151449205676"},"user_tz":240},"id":"Aha1PVWKSz_K","outputId":"916bbf15-a51a-48af-904a-deb353c799d2"},"outputs":[{"output_type":"stream","name":"stdout","text":["GPU is available and set to: Tesla T4\n"]}],"source":["import torch\n","\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    print(\"GPU is available and set to:\", torch.cuda.get_device_name(0))\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"GPU not available, using CPU instead.\")"]},{"cell_type":"markdown","metadata":{"id":"PgiNF2MFQTfW"},"source":["#### Pip Install"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4309,"status":"ok","timestamp":1716667456702,"user":{"displayName":"Maanav Rajesh","userId":"00079058151449205676"},"user_tz":240},"id":"B9CnGqpiQBOq","outputId":"679ec3cf-75a5-4c75-ca4c-d6f4ff1c18bb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: rasterio in /usr/local/lib/python3.10/dist-packages (1.3.10)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n","Requirement already satisfied: geopandas in /usr/local/lib/python3.10/dist-packages (0.13.2)\n","Requirement already satisfied: affine in /usr/local/lib/python3.10/dist-packages (from rasterio) (2.4.0)\n","Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (23.2.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2024.2.2)\n","Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.7)\n","Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio) (0.7.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.25.2)\n","Requirement already satisfied: snuggs>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.4.7)\n","Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.1.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from rasterio) (67.7.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: fiona>=1.8.19 in /usr/local/lib/python3.10/dist-packages (from geopandas) (1.9.6)\n","Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (2.0.3)\n","Requirement already satisfied: pyproj>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from geopandas) (3.6.1)\n","Requirement already satisfied: shapely>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from geopandas) (2.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (1.16.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->geopandas) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->geopandas) (2024.1)\n"]}],"source":["!pip install rasterio matplotlib geopandas\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1840,"status":"ok","timestamp":1716667458532,"user":{"displayName":"Maanav Rajesh","userId":"00079058151449205676"},"user_tz":240},"id":"Hd9COeW0TyvU","outputId":"3d7baf16-e7ec-4ac3-871e-1183ed81d425"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1716667458532,"user":{"displayName":"Maanav Rajesh","userId":"00079058151449205676"},"user_tz":240},"id":"8H3OQ5avU6YI","outputId":"ac29dbfb-db4a-4302-b2ba-f0e6a03e05e3"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1MNSgACFZBntIhsetYbiUztFCcTtX8ZoD/MAG_Wildfire_Hackathon/Wildfire_Hackathon_Complete\n"]}],"source":["%cd '/content/drive/MyDrive/MAG_Wildfire_Hackathon/Wildfire_Hackathon_Complete'"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":838,"status":"ok","timestamp":1716667459364,"user":{"displayName":"Maanav Rajesh","userId":"00079058151449205676"},"user_tz":240},"id":"dbu6nvBzVIHz","outputId":"d7f314e1-dea2-44a6-a358-ae37dff2d2cf"},"outputs":[{"output_type":"stream","name":"stdout","text":["'0.load data -- Aania edits.ipynb'   demo-MVP-Aaryaman.ipynb\t output\n","'0. load data.ipynb'\t\t    'demo-MVP-BEST ONE.ipynb'\t test\n","'1. demo-MVP.ipynb'\t\t     demo-MVP-bilaledits.ipynb\t train\n"," Aadi.ipynb\t\t\t     demo-MVP-maanav1.ipynb\t'Untitled presentation.gslides'\n"," Aaditya.ipynb\t\t\t     demo-MVP-maanav.ipynb\t wildfire-hackathon-kaggle.zip\n"," Aania_forecast.ipynb\t\t     fbp_lookup.csv\n"," demo-MVP-Aania.ipynb\t\t     hotspots\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1716667459365,"user":{"displayName":"Maanav Rajesh","userId":"00079058151449205676"},"user_tz":240},"id":"-ApU65vbPuBW"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import geopandas as gpd\n","import rasterio as rio\n","import os\n","import torch\n","from torch.utils.data import Dataset\n","from torchvision import transforms\n","import torch.optim as optim\n","from tqdm import tqdm\n","import torch.nn.functional as F\n","\n","# Paths for data and fires\n","data_path = \"./\"\n","train_path = data_path + \"train/\"\n","test_path = data_path + \"test/\"\n","tr_fnums = [\"fire1209\", \"fire1298\", \"fire1386\", \"fire2034\", \"fire2210\", \"fire2211\", \"fire2212\"]\n","te_fnums = [\"fire2214\"]"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1716667459365,"user":{"displayName":"Maanav Rajesh","userId":"00079058151449205676"},"user_tz":240},"id":"zdg7CoUSPuBY"},"outputs":[],"source":["# Util variables\n","device = 'cuda'\n","target_shape = (528, 720)\n","\n","# Util functions\n","def pad_to_fit(d, shape):\n","    h, w = d.shape\n","    pad_h = shape[0] - h\n","    pad_w = shape[1] - w\n","    if pad_h > 0 or pad_w > 0:\n","        pad_top = pad_h // 2\n","        pad_bottom = pad_h - pad_top\n","        pad_left = pad_w // 2\n","        pad_right = pad_w - pad_left\n","\n","        d = np.pad(d, ((pad_top, pad_bottom), (pad_left, pad_right)), mode='constant', constant_values=0)\n","    return d\n","\n","def normalize(d):\n","    m = np.mean(d)\n","    s = np.std(d)\n","    return (d - m)/s\n","\n","def tif2np(tif):\n","    with rio.open(tif) as src:\n","        data = src.read(1)  # Read the first band\n","    return pad_to_fit(np.nan_to_num(data, nan=0.0), target_shape)"]},{"cell_type":"markdown","metadata":{"id":"zV0jwxbdPuBY"},"source":["## Functions to load data\n","\n","The load fire function loads and processes data for the denoted fire. The fire is then stacked into a numpy array.\n","\n","The load day function loads in a day of data for a specified fire.\n","\n","<ins>**Additional data should be loaded and specified into this function**.<ins>"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"WZOXaE5ieI95","executionInfo":{"status":"ok","timestamp":1716667459365,"user_tz":240,"elapsed":7,"user":{"displayName":"Maanav Rajesh","userId":"00079058151449205676"}}},"outputs":[],"source":["#import geopandas as gpd\n","\n","#fire1209_shp = gpd.read_file('/content/drive/MyDrive/MAG_Wildfire_Hackathon/Wildfire_Hackathon_Complete/train/fire1209/fire/fire1209.shp')\n","# fire1209.ignition"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"0sMbnwxte_QZ","executionInfo":{"status":"ok","timestamp":1716667459365,"user_tz":240,"elapsed":7,"user":{"displayName":"Maanav Rajesh","userId":"00079058151449205676"}}},"outputs":[],"source":["#fire1209_shp"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1716667459365,"user":{"displayName":"Maanav Rajesh","userId":"00079058151449205676"},"user_tz":240},"id":"sVipJu5IPuBY"},"outputs":[],"source":["def load_day(path, day):\n","    # weather relative humidity\n","    wrh = path+'/weather/noon_relative_humidity_day{}.tif'.format(day)\n","    wrh = normalize(tif2np(wrh))\n","    # weather wind speed\n","    wws = path+'/weather/noon_wind_speed_day{}.tif'.format(day)\n","    wws = normalize(tif2np(wws))\n","    # Add more data here\n","    ap24 = path+'/weather/24hr_accumulated_precipitation_day{}.tif'.format(day)\n","    ap24 = normalize(tif2np(ap24))\n","\n","    mt24 = path+'/weather/24hr_max_temperature_day{}.tif'.format(day)\n","    mt24 = normalize(tif2np(mt24))\n","\n","    nt = path+'/weather/noon_temperature_day{}.tif'.format(day)\n","    nt = normalize(tif2np(nt))\n","\n","    nwd = path+'/weather/noon_wind_direction_day{}.tif'.format(day)\n","    nwd = normalize(tif2np(nwd))\n","\n","    # fire_weather\n","    fwi = path+'/fire_weather/fire_weather_index_day{}.tif'.format(day)\n","    fwi = normalize(tif2np(fwi))\n","    # weather buildup index day\n","    wbi = path+'/fire_weather/build_up_index_day{}.tif'.format(day)\n","    wbi = normalize(tif2np(wbi))\n","    # drought codeday\n","    dcd = path+'/fire_weather/drought_code_day{}.tif'.format(day)\n","    dcd = normalize(tif2np(dcd))\n","    # moisture code\n","    dfc = path+'/fire_weather/duff_moisture_code_day{}.tif'.format(day)\n","    dfc = normalize(tif2np(dfc))\n","    # initial spread\n","    isi = path+'/fire_weather/initial_spread_index_day{}.tif'.format(day)\n","    isi = normalize(tif2np(isi))\n","\n","    ffm = path+'/fire_weather/fine_fuel_moisture_code_day{}.tif'.format(day)\n","    ffm = normalize(tif2np(ffm))\n","\n","#   return [wrh, wws, mt24, ap24, nt, nwd, fwi, wbi, dcd, dfc, isi, ffm]\n","    return [wrh, wws, mt24, nt, nwd, fwi, isi]\n","\n","def load_fire(fire_num, split = \"Train\"):\n","    path = train_path + fire_num\n","    if split == \"Test\":\n","        path = test_path + fire_num\n","\n","    ftif = path + \"/fire/{}.tif\".format(fire_num)\n","    if split == \"Test\":\n","        ftif = path + \"/fire/{}_train.tif\".format(fire_num)\n","    fdata = tif2np(ftif)\n","\n","    minjd, maxjd = int(np.min(fdata[np.nonzero(fdata)])), int(np.max(fdata))\n","    lastjd = maxjd\n","    if split == \"Test\":\n","        maxjd += 21\n","\n","    elev = normalize(tif2np(path+'/topography/dem.tif'))\n","    slope = normalize(tif2np(path+'/topography/slope.tif'))\n","    # review fuels to keep\n","    fuels = tif2np(path+'/fuels/fbp_fuels.tif')\n","    ignition = tif2np(path+'/fire/ignitions.tif')\n","\n","\n","    dataset = []\n","    gt = ignition\n","    cfire = ignition\n","    for d in range(minjd, maxjd):\n","        data = {}\n","\n","        fuels[cfire != 0] = 0\n","        ft = [fuels]\n","        ft.extend([cfire, gt, slope, elev])\n","        ft.extend(load_day(path, d))\n","        ft = np.stack(ft)\n","        data['ft'] = ft\n","\n","        if d < lastjd:\n","            gt = fdata == float(d)\n","            data['gt'] = gt\n","\n","        cfire = np.logical_or(cfire ,gt)\n","\n","        dataset.append(data)\n","    return dataset"]},{"cell_type":"markdown","metadata":{"id":"rsYNHXHWPuBZ"},"source":["## Create the datasets and dataloaders\n","\n","<ins>Create/implement data augmentations/transformations here<ins>"]},{"cell_type":"markdown","metadata":{"id":"bcY7tnjOPuBZ"},"source":["## Define the network/model\n","\n","In this example, we define a simple 2 layer cnn model.\n","\n","<ins>**Modify the model as you see fit!**<ins>"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":256903,"status":"ok","timestamp":1716667716263,"user":{"displayName":"Maanav Rajesh","userId":"00079058151449205676"},"user_tz":240},"id":"A_jb7z0IPuBZ","outputId":"bf0f6be1-74df-4715-e923-9855c8686356"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-18-5d052e1dc572>:22: RuntimeWarning: invalid value encountered in divide\n","  return (d - m)/s\n"]},{"output_type":"stream","name":"stdout","text":["245\n","30\n"]}],"source":["class FireDataset(Dataset):\n","    def __init__(self, split=\"Train\"):\n","        fnums = tr_fnums if split==\"Train\" else te_fnums\n","        self.dataset = []\n","        for fnum in fnums:\n","            self.dataset.extend(load_fire(fnum, split=split))\n","        print(len(self.dataset))\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","    def __getitem__(self, idx):\n","        return self.dataset[idx]\n","\n","trainset = FireDataset(split=\"Train\")\n","trainset, valset = torch.utils.data.random_split(trainset, [0.9,0.1])\n","testset = FireDataset(split=\"Test\")\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=8, shuffle=True)\n","valloader = torch.utils.data.DataLoader(valset, batch_size=8, shuffle=True)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False)"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"zV7hgoAKPuBZ","executionInfo":{"status":"ok","timestamp":1716667716265,"user_tz":240,"elapsed":10,"user":{"displayName":"Maanav Rajesh","userId":"00079058151449205676"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","class FuelEmbeddings(nn.Module):\n","    def __init__(self, embedding_dim):\n","        super(FuelEmbeddings, self).__init__()\n","\n","        unique_values = [0, 1, 2, 3, 4, 7, 13, 31, 101, 425, 635, 650, 665]\n","        self.unique_values = torch.tensor(unique_values).to(device)  # Unique values in the categorical feature\n","        self.embedding_dim = embedding_dim\n","        self.embedding = nn.Embedding(num_embeddings=len(unique_values), embedding_dim=embedding_dim)\n","\n","    def forward(self, categorical_feature):\n","        # (B,H,W) -> (B,H,W,U) wher U is unique values count\n","        mask = categorical_feature.unsqueeze(-1) == self.unique_values\n","        matching_indices = torch.argmax(mask.int(), dim=-1)\n","\n","        # Apply embedding and reshape\n","        # (B,H,W,U) -> (B,H,W,6) -> (B,6,H,W) in default setting\n","        embedded_fuel = self.embedding(matching_indices)\n","        embedded_reshaped_fuel = embedded_fuel.permute(0, 3, 1, 2)\n","\n","        return embedded_reshaped_fuel\n","\n","class CNN1(nn.Module):\n","    def __init__(self, embedding_dim=6, num_features=8):\n","        super(CNN1, self).__init__()\n","\n","        self.fuelembedding = FuelEmbeddings(embedding_dim)\n","\n","        # (266, 433)\n","        self.conv_block1 = nn.Sequential(\n","            nn.Conv2d(in_channels=(embedding_dim+num_features-1), out_channels=8, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(num_features=8),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(num_features=16),\n","            nn.ReLU(inplace=True)\n","        )\n","        self.conv_block2 = nn.Sequential(\n","            nn.Conv2d(in_channels=16, out_channels=8, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(num_features=8),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(in_channels=8, out_channels=1, kernel_size=3, stride=1, padding=1)\n","        )\n","        self.conv_block3 = nn.Sequential(\n","            nn.Conv2d(in_channels=16, out_channels=8, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(num_features=8),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(in_channels=8, out_channels=1, kernel_size=3, stride=1, padding=1)\n","        )\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        categorical_feature = x[:, 0, :, :]  # Extract the categorical feature\n","        embedded_fuel = self.fuelembedding(categorical_feature)  # Transform the categorical feature\n","\n","        # Replace the original categorical feature with the embedded feature\n","        x = torch.cat((embedded_fuel, x[:, 1:, :, :]), dim=1)\n","\n","        x = self.conv_block1(x)\n","        x = self.conv_block2(x)\n","        out = self.sigmoid(x)\n","\n","        return out\n"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"pB1YPTwA3j-7","executionInfo":{"status":"ok","timestamp":1716667716265,"user_tz":240,"elapsed":8,"user":{"displayName":"Maanav Rajesh","userId":"00079058151449205676"}}},"outputs":[],"source":["class FuelEmbeddings(nn.Module):\n","    def __init__(self, embedding_dim):\n","        super(FuelEmbeddings, self).__init__()\n","\n","        unique_values = [0, 1, 2, 3, 4, 7, 13, 31, 101, 425, 635, 650, 665]\n","        self.unique_values = torch.tensor(unique_values)  # Unique values in the categorical feature\n","        self.embedding_dim = embedding_dim\n","        self.embedding = nn.Embedding(num_embeddings=len(unique_values), embedding_dim=embedding_dim)\n","\n","    def forward(self, categorical_feature):\n","        # (B,H,W) -> (B,H,W,U) where U is unique values count\n","        mask = categorical_feature.unsqueeze(-1) == self.unique_values\n","        matching_indices = torch.argmax(mask.int(), dim=-1)\n","\n","        # Apply embedding and reshape\n","        # (B,H,W,U) -> (B,H,W,embedding_dim) -> (B,embedding_dim,H,W) in default setting\n","        embedded_fuel = self.embedding(matching_indices)\n","        embedded_reshaped_fuel = embedded_fuel.permute(0, 3, 1, 2)\n","\n","        return embedded_reshaped_fuel\n","\n","class LogisticRegressionModel(nn.Module):\n","    def __init__(self, embedding_dim=6, num_features=12):\n","        super(LogisticRegressionModel, self).__init__()\n","\n","        self.fuelembedding = FuelEmbeddings(embedding_dim)\n","\n","        # Calculate the input dimensions for the linear layer\n","        # Assuming the input height and width are 266 and 433 respectively\n","        height = 266\n","        width = 433\n","        self.input_dim = embedding_dim * height * width + (num_features - 1) * height * width\n","\n","        # Define the linear layer with the calculated input dimension and 1 output\n","        self.linear = nn.Linear(self.input_dim, 1)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        categorical_feature = x[:, 0, :, :]  # Extract the categorical feature\n","        embedded_fuel = self.fuelembedding(categorical_feature)  # Transform the categorical feature\n","\n","        # Replace the original categorical feature with the embedded feature\n","        x = torch.cat((embedded_fuel, x[:, 1:, :, :]), dim=1)\n","\n","        # Debugging print statements\n","        print(f\"Shape after embedding and concatenation: {x.shape}\")\n","\n","        # Flatten the input for the linear layer\n","        x = x.view(x.size(0), -1)\n","\n","        # Debugging print statements\n","        print(f\"Shape after flattening: {x.shape}\")\n","\n","        x = self.linear(x)\n","        out = self.sigmoid(x)\n","\n","        return out"]},{"cell_type":"markdown","metadata":{"id":"mLleR-YIPuBa"},"source":["## Define Loss function\n","\n","<ins>**Create/define/specify your own loss function here!**<ins>"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"FJmeNfXzPuBa","executionInfo":{"status":"ok","timestamp":1716667716266,"user_tz":240,"elapsed":8,"user":{"displayName":"Maanav Rajesh","userId":"00079058151449205676"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","class IoULoss(nn.Module):\n","    def __init__(self, threshold=0.5):\n","        super(IoULoss, self).__init__()\n","        self.threshold = threshold\n","\n","    def forward(self, outputs, labels):\n","        # threshold condition is not differentiable so just use softmaxed data\n","        # Flatten the tensors\n","        outputs = outputs.view(-1)\n","        labels = labels.view(-1)\n","\n","        # Compute the intersection\n","        intersection = (outputs * labels).sum()\n","\n","        # Compute the union\n","        union = outputs.sum() + labels.sum() - intersection\n","        iou = intersection / (union + 1e-6)  # Add a small epsilon for numerical stability\n","        loss = 1 - iou\n","        return loss"]},{"cell_type":"markdown","metadata":{"id":"WGS8w27tPuBa"},"source":["#### Metrics for evaluation"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"HYJGWyZNPuBa","executionInfo":{"status":"ok","timestamp":1716667717412,"user_tz":240,"elapsed":1154,"user":{"displayName":"Maanav Rajesh","userId":"00079058151449205676"}}},"outputs":[],"source":["from sklearn.metrics import accuracy_score, jaccard_score, f1_score"]},{"cell_type":"markdown","metadata":{"id":"hzJ62kc5PuBa"},"source":["#### Train function"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"v74GfH_5PuBb","executionInfo":{"status":"ok","timestamp":1716667717412,"user_tz":240,"elapsed":6,"user":{"displayName":"Maanav Rajesh","userId":"00079058151449205676"}}},"outputs":[],"source":["# Train\n","def train(model, dataloader, optimizer, criterion):\n","    model.train()\n","    running_loss = 0\n","    total_steps = 0\n","    for i, batch in enumerate(dataloader):\n","        ft = batch['ft'].to(device).float()\n","        gt = batch['gt'].to(device).float()\n","\n","        optimizer.zero_grad()\n","        output = model(ft).squeeze()\n","\n","        loss = criterion(output, gt)\n","\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","        total_steps += 1\n","    return running_loss/total_steps"]},{"cell_type":"markdown","metadata":{"id":"ZHfv9lHEPuBb"},"source":["#### Eval function"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"iMkdEWknPuBb","executionInfo":{"status":"ok","timestamp":1716667717412,"user_tz":240,"elapsed":5,"user":{"displayName":"Maanav Rajesh","userId":"00079058151449205676"}}},"outputs":[],"source":["def eval(model, dataloader):\n","    model.eval()\n","    acc = []\n","    iou = []\n","    f1 = []\n","    total_steps = 0\n","    with torch.no_grad():\n","        for i, batch in enumerate(dataloader):\n","            ft = batch['ft'].to(device)\n","            gt = torch.flatten(batch['gt'])\n","\n","            output = torch.flatten(model(ft)).squeeze().cpu()\n","            output = (output > 0.5)\n","\n","            acc.append(accuracy_score(gt, output))\n","            iou.append(jaccard_score(gt, output))\n","            f1.append(f1_score(gt, output))\n","            total_steps += 1\n","    return sum(acc)/total_steps, sum(iou)/total_steps, sum(f1)/total_steps"]},{"cell_type":"markdown","metadata":{"id":"qnYgHTBfPuBb"},"source":["#### Inference function\n","\n","Saves the inference results to a submission file!"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"LqLima1jPuBb","executionInfo":{"status":"ok","timestamp":1716667717413,"user_tz":240,"elapsed":6,"user":{"displayName":"Maanav Rajesh","userId":"00079058151449205676"}}},"outputs":[],"source":["def inference(model, dataloader):\n","    model.eval()\n","    with torch.no_grad():\n","        cfire = torch.zeros(target_shape)\n","        for i, day in enumerate(dataloader):\n","            ft = day['ft'].to(device)\n","\n","            # Create the submission file after 10 days\n","            if i > 9:\n","                cfire = torch.logical_or(output, cfire) # define the cumulative fire\n","                ft[0][1] = cfire # set the cumulative fire for the next input\n","                ft[0][2] = output # set the next step fire for the next input\n","            else:\n","                cfire = ft[0][1]\n","\n","            output = model(ft)\n","            output = (output > 0.5)\n","\n","    # Save the cumulative fire\n","    pred = cfire.cpu().squeeze().numpy()\n","    save_df = pd.DataFrame(pred)  # convert img data to df\n","    save_df.to_csv(\"./output/submission.csv\", index_label='row')\n","    return pred"]},{"cell_type":"markdown","metadata":{"id":"eHfpPQqdPuBb"},"source":["#### The training/eval/inference loop\n","\n","<ins>**Define new optimizers here**<ins>\n","\n","<ins>**Utilize a scheduler here**<ins>\n","\n","<ins>**Change the learning rate here**<ins>\n","\n","<ins>**Implement a better early stopping strategy here**<ins>\n","\n","<ins>**Implement other tricks here (i.e. EMA)**<ins>\n"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"SswqAmFo8Sql","executionInfo":{"status":"ok","timestamp":1716667717413,"user_tz":240,"elapsed":5,"user":{"displayName":"Maanav Rajesh","userId":"00079058151449205676"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","class FuelEmbeddings(nn.Module):\n","    def __init__(self, embedding_dim):\n","        super(FuelEmbeddings, self).__init__()\n","\n","        unique_values = [0, 1, 2, 3, 4, 7, 13, 31, 101, 425, 635, 650, 665]\n","        self.unique_values = torch.tensor(unique_values).to(device)  # Unique values in the categorical feature\n","        self.embedding_dim = embedding_dim\n","        self.embedding = nn.Embedding(num_embeddings=len(unique_values), embedding_dim=embedding_dim)\n","\n","    def forward(self, categorical_feature):\n","        # (B,H,W) -> (B,H,W,U) where U is unique values count\n","        mask = categorical_feature.unsqueeze(-1) == self.unique_values\n","        matching_indices = torch.argmax(mask.int(), dim=-1)\n","\n","        # Apply embedding and reshape\n","        # (B,H,W,U) -> (B,H,W,embedding_dim) -> (B,embedding_dim,H,W) in default setting\n","        embedded_fuel = self.embedding(matching_indices)\n","        embedded_reshaped_fuel = embedded_fuel.permute(0, 3, 1, 2)\n","\n","        return embedded_reshaped_fuel\n","\n","class CNN1(nn.Module):\n","    def __init__(self, embedding_dim=6, num_features=12):\n","        super(CNN1, self).__init__()\n","\n","        self.fuelembedding = FuelEmbeddings(embedding_dim)\n","\n","        # Complex CNN Architecture\n","        self.conv_block1 = nn.Sequential(\n","            nn.Conv2d(in_channels=(embedding_dim+num_features-1), out_channels=16, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(num_features=16),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(num_features=32),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","        )\n","\n","        self.conv_block2 = nn.Sequential(\n","            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(num_features=64),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(num_features=128),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","        )\n","\n","        self.conv_block3 = nn.Sequential(\n","            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(num_features=256),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(num_features=512),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","        )\n","\n","        self.fc = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(512 * 33 * 54, 1024),  # Adjusted the size according to the pooling layers\n","            nn.ReLU(inplace=True),\n","            nn.Linear(1024, 1)\n","        )\n","\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        categorical_feature = x[:, 0, :, :]  # Extract the categorical feature\n","        embedded_fuel = self.fuelembedding(categorical_feature)  # Transform the categorical feature\n","\n","        # Replace the original categorical feature with the embedded feature\n","        x = torch.cat((embedded_fuel, x[:, 1:, :, :]), dim=1)\n","\n","        x = self.conv_block1(x)\n","        x = self.conv_block2(x)\n","        x = self.conv_block3(x)\n","        x = self.fc(x)\n","        out = self.sigmoid(x)\n","\n","        return out\n","\n"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"executionInfo":{"elapsed":12167,"status":"error","timestamp":1716667729575,"user":{"displayName":"Maanav Rajesh","userId":"00079058151449205676"},"user_tz":240},"id":"2G957mSAPuBb","outputId":"dd7de6ba-78b1-499c-99b7-9d350ef1052d"},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"mat1 and mat2 shapes cannot be multiplied (8x3041280 and 912384x1024)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-a1514776e7a5>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mbest_miou\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0maa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmiou\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-27-855b75d794ba>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer, criterion)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-30-95742149fdc1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_block2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_block3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (8x3041280 and 912384x1024)"]}],"source":["model = CNN1(num_features=12)\n","# model = LogisticRegressionModel(embedding_dim=8, num_features=12)\n","model.to(device)\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","criterion = IoULoss()\n","epochs = 20\n","best_miou = 0\n","for e in range(epochs):\n","    loss = train(model, trainloader, optimizer, criterion)\n","    aa, miou, mf1 = eval(model,valloader)\n","\n","    if miou > best_miou:\n","        best_miou = miou\n","        cfire = inference(model, testloader)\n","        e = str(e)+\"*\"\n","    print(e, \" avg iou loss:{:.3f} avg acc: {:.3f} avg f1: {:.3f} avg iou jaccard score: {:.3f}\".format(loss, aa, mf1, miou))\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Bkdf3fewPuBb"},"source":["## Other Ideas to implement!\n","\n","<ins>**Ensemble learning - voting**<ins>\n","\n","<ins>**Implement hot spot data pipeline**<ins>\n","\n","<ins>**Make better use of temporal data**<ins>\n","\n","<ins>**Get creative!**<ins>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QmhVKs3hvhrM","executionInfo":{"status":"aborted","timestamp":1716667729576,"user_tz":240,"elapsed":6,"user":{"displayName":"Maanav Rajesh","userId":"00079058151449205676"}}},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":0}